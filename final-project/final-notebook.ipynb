{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Bayesian Neural Networks for semi-supervised Representation Learning and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "content goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary libraries\n",
    "%matplotlib inline\n",
    "from edward.util import Progbar\n",
    "import tensorflow as tf\n",
    "from utils import (generator_xy, generator, \n",
    "                   load_data, accuracy, visulize,)\n",
    "import edward as ed\n",
    "import numpy as np\n",
    "from AE import encoder, decoder, mlp, NN_classifier\n",
    "from observations import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from edward.models import Normal, Bernoulli, Categorical\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "content goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed.set_seed(100)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.as_default()\n",
    "M = 12000\n",
    "(x_train, y_train), (x_test, y_test) = mnist('./data')\n",
    "y_train = tf.cast(y_train, tf.int32).eval()\n",
    "y_test = tf.cast(y_test, tf.int32).eval()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train_AE = load_data('../snp_gen/data/encoded_train_AE.pkl')\n",
    "x_test_AE = load_data('../snp_gen/data/encoded_test_AE.pkl')\n",
    "x_train_BAE = load_data('../snp_gen/data/encoded_train_BAE.pkl')\n",
    "x_test_BAE = load_data('../snp_gen/data/encoded_test_BAE.pkl')\n",
    "x_train_generator = generator_xy([x_train,y_train], M)\n",
    "x_train_generator_AE = generator_xy([x_train_AE, y_train], M)\n",
    "x_train_generator_BAE = generator_xy([x_train_BAE, y_train], M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAABECAYAAACCozEKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f137adae240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visulize(10, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "content goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image of the model goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Bayesian Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model here\n",
    "num_hidden = 100\n",
    "D = 256\n",
    "num_class = 10\n",
    "\n",
    "W_0 = Normal(loc = tf.zeros([D, num_hidden]), scale = tf.ones([D, num_hidden]))\n",
    "W_1 = Normal(loc = tf.zeros([num_hidden, num_class]), scale = tf.ones([num_hidden,num_class]))\n",
    "b_0 = Normal(loc = tf.zeros(num_hidden), scale = tf.ones(num_hidden))\n",
    "b_1 = Normal(loc = tf.zeros(num_class), scale = tf.ones(num_class))\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, D])\n",
    "\n",
    "y = Categorical(logits=NN_classifier(x, W_0, W_1, b_0, b_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the variational model here\n",
    "qW_0 = Normal(loc = tf.Variable(tf.random_normal([D,num_hidden])),\n",
    "                  scale = tf.nn.softplus(tf.Variable(tf.random_normal([D,num_hidden]))))\n",
    "qW_1 = Normal(loc = tf.Variable(tf.random_normal([num_hidden,num_class])),\n",
    "                  scale = tf.nn.softplus(tf.Variable(tf.random_normal([num_hidden,num_class]))))\n",
    "qb_0 = Normal(loc = tf.Variable(tf.random_normal([num_hidden])),\n",
    "                  scale = tf.nn.softplus(tf.Variable(tf.random_normal([num_hidden]))))\n",
    "qb_1 = Normal(loc = tf.Variable(tf.random_normal([num_class])),\n",
    "                   scale = tf.nn.softplus(tf.Variable(tf.random_normal([num_class]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Inference and Critisism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferece initilization for AE representation\n",
    "inference = ed.KLqp({W_0:qW_0, b_0:qb_0,\n",
    "                    W_1:qW_1, b_1:qb_1}, \n",
    "                    data = {x: x_train_AE, y: y_train})\n",
    "inference.initialize(n_iter = 1000, n_samples = 5)\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.12776666666666667\n",
      "testing accuracy:\n",
      "0.1364\n"
     ]
    }
   ],
   "source": [
    "# prior draw and prediction accuracy for AE representation\n",
    "pri_qW_0 = qW_0.sample()\n",
    "pri_qW_1 = qW_1.sample()\n",
    "pri_qb_0 = qb_0.sample()\n",
    "pri_qb_1 = qb_1.sample()\n",
    "\n",
    "prior_weights = [pri_qW_0, pri_qW_1, pri_qb_0, pri_qb_1] \n",
    "\n",
    "print(\"training accuracy:\")\n",
    "print(accuracy(x_train_AE, y_train, prior_weights))\n",
    "print(\"testing accuracy:\")\n",
    "print(accuracy(x_test_AE, y_test, prior_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'log_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-93a7f2d48a01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_iter_per_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mlog_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-log p(x) <= {:0.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_loss' is not defined"
     ]
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "n_iter_per_epoch = x_train_AE.shape[0] // M\n",
    "loss = []\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    print(\"Epoch: {0}\".format(epoch))\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    # pbar = Progbar(n_iter_per_epoch)\n",
    "    for t in range(1, n_iter_per_epoch + 1):\n",
    "        # pbar.update(t)\n",
    "        x_batch, y_batch = next(x_train_generator_AE)\n",
    "        info_dict = inference.update(feed_dict={x: x_batch, y: y_batch})\n",
    "        avg_loss += info_dict['loss']\n",
    "        avg_loss = avg_loss / n_iter_per_epoch\n",
    "        avg_loss = avg_loss / M\n",
    "        loss.append(-avg_loss)\n",
    "    print(\"-log p(x) <= {:0.3f}\".format(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loss plot\n",
    "plt.plot(range(n_epoch), loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior accuracy check for AE representation\n",
    "pos_qW_0 = qW_0.sample()\n",
    "pos_qW_1 = qW_1.sample()\n",
    "pos_qb_0 = qb_0.sample()\n",
    "pos_qb_1 = qb_1.sample()\n",
    "\n",
    "posterior_weights = [pos_qW_0, pos_qW_1, pos_qb_0, pos_qb_1] \n",
    "\n",
    "print(\"training accuracy:\")\n",
    "print(accuracy(x_train_AE, y_train, prior_weights))\n",
    "print(\"testing accuracy:\")\n",
    "print(accuracy(x_test_AE, y_test, prior_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferece initilization for Bayesian AE representation\n",
    "inference = ed.KLqp({W_0:qW_0, b_0:qb_0,\n",
    "                    W_1:qW_1, b_1:qb_1}, \n",
    "                    data = {x: x_train_BAE, y: y_train})\n",
    "inference.initialize(n_iter = 1000, n_samples = 5)\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior draw and prediction accuracy for Bayesian AE representation\n",
    "pri_qW_0 = qW_0.sample()\n",
    "pri_qW_1 = qW_1.sample()\n",
    "pri_qb_0 = qb_0.sample()\n",
    "pri_qb_1 = qb_1.sample()\n",
    "\n",
    "prior_weights = [pri_qW_0, pri_qW_1, pri_qb_0, pri_qb_1] \n",
    "\n",
    "print(\"training accuracy:\")\n",
    "print(accuracy(x_train_BAE, y_train, prior_weights))\n",
    "print(\"testing accuracy:\")\n",
    "print(accuracy(x_test_BAE, y_test, prior_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "n_iter_per_epoch = x_train_BAE.shape[0] // M\n",
    "log_loss = []\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    print(\"Epoch: {0}\".format(epoch))\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    # pbar = Progbar(n_iter_per_epoch)\n",
    "    for t in range(1, n_iter_per_epoch + 1):\n",
    "        # pbar.update(t)\n",
    "        x_batch, y_batch = next(x_train_generator_BAE)\n",
    "        info_dict = inference.update(feed_dict={x: x_batch, y: y_batch})\n",
    "        avg_loss += info_dict['loss']\n",
    "        avg_loss = avg_loss / n_iter_per_epoch\n",
    "        avg_loss = avg_loss / M\n",
    "        log_loss.append(-avg_loss)\n",
    "    print(\"-log p(x) <= {:0.3f}\".format(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior accuracy check for Bayesian AE representation\n",
    "pos_qW_0 = qW_0.sample()\n",
    "pos_qW_1 = qW_1.sample()\n",
    "pos_qb_0 = qb_0.sample()\n",
    "pos_qb_1 = qb_1.sample()\n",
    "\n",
    "posterior_weights = [pos_qW_0, pos_qW_1, pos_qb_0, pos_qb_1] \n",
    "\n",
    "print(\"training accuracy:\")\n",
    "print(accuracy(x_train_BAE, y_train, prior_weights))\n",
    "print(\"testing accuracy:\")\n",
    "print(accuracy(x_test_BAE, y_test, prior_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loss plot\n",
    "plt.plot(range(n_epoch), loss)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
