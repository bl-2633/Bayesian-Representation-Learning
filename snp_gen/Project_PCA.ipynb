{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/foo/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#Import all the necessary packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "from edward.models import Normal, BernoulliWithSigmoidProbs, Bernoulli, Dirichlet, Empirical\n",
    "from edward.util import Progbar\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as pyplot\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic PCA with variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All dimension of input data ranges from [-1, 1]\n",
    "#thus motivating usages of non-Gaussian noises\n",
    "#Input: \n",
    "#DATA, the data dimension to be reduced\n",
    "#latent_dim, the latent dimension\n",
    "#dimension_reduction_coef_var, the variance of the coefficients\n",
    "#observation_var, \n",
    "#sigmoid: whether the sigmoid is used before/after addition of noise, or not used\n",
    "#inference_method: the method to infer the latent variables, klqp and HMC implemented\n",
    "#Output:\n",
    "#qw: the \"posterior\" of dimension reduction coefficients\n",
    "#qz: the \"posterior\" of latent variables\n",
    "def unsupervised_dimension_reduction(DATA, latent_dim, dimension_reduction_coef_var, \n",
    "                                    observation_var, sigmoid='last', inference_method='KLqp'):\n",
    "    sample_size = DATA.shape[0]\n",
    "    correlation_count = DATA.shape[1]\n",
    "    if sigmoid:\n",
    "        observation_var = None\n",
    "    w = Normal(loc=tf.zeros([correlation_count, latent_dim]), \n",
    "               scale=dimension_reduction_coef_var * tf.ones([correlation_count, latent_dim]))\n",
    "    z = Normal(loc=tf.zeros([sample_size, latent_dim]), \n",
    "               scale=tf.ones([sample_size, latent_dim]))\n",
    "    targets = None\n",
    "    if sigmoid == 'last':\n",
    "        logits = Normal(loc=tf.matmul(w, z, transpose_b=True), \n",
    "                   scale=observation_var * tf.ones([correlation_count, sample_size]))\n",
    "        t = tf.sigmoid(logits)\n",
    "        targets = 2 * t - 1\n",
    "    elif sigmoid == 'no_sigmoid':\n",
    "        targets = Normal(loc=tf.matmul(w, z, transpose_b=True), \n",
    "                   scale=observation_var * tf.ones([correlation_count, sample_size]))\n",
    "    elif sigmoid == 'first':\n",
    "        t = tf.sigmoid(tf.matmul(w, z, transpose_b=True))\n",
    "        t = 2 * t - 1\n",
    "        targets = Normal(loc=t, \n",
    "                         scale=observation_var * tf.ones([correlation_count, sample_size]))\n",
    "    qw = Normal(loc=tf.Variable(tf.random_normal([correlation_count, latent_dim])),\n",
    "            scale=tf.nn.softplus(tf.Variable(tf.random_normal([correlation_count, latent_dim]))))\n",
    "    qz = Normal(loc=tf.Variable(tf.random_normal([sample_size, latent_dim])),\n",
    "            scale=tf.nn.softplus(tf.Variable(tf.random_normal([sample_size, latent_dim]))))\n",
    "    inference = ed.KLqp({w: qw, z: qz}, data={targets: DATA.T})\n",
    "    inference.run(n_iter=500, n_print=100, n_samples=100)\n",
    "    return qw, qz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All dimension of input data ranges from [-1, 1]\n",
    "#thus motivating usages of non-Gaussian noises\n",
    "#Input: \n",
    "#DATA, the data dimension to be reduced\n",
    "#qw: the probability distribution dimension reduction coefficients\n",
    "#latent_dim, the latent dimension\n",
    "#dimension_reduction_coef_var, the variance of the coefficients\n",
    "#observation_var, \n",
    "#sigmoid: whether the sigmoid is used before/after addition of noise, or not used\n",
    "#inference_method: the method to infer the latent variables, klqp and HMC implemented\n",
    "#Output:\n",
    "#qw: the \"posterior\" of dimensino reduction coefficients\n",
    "#qz: the \"posterior\" of latent variables\n",
    "def learn_latent_given_w(DATA, qw, latent_dim, observation_var, sigmoid=False):\n",
    "    sample_size = DATA.shape[0]\n",
    "    correlation_count = DATA.shape[1]\n",
    "    z = Normal(loc=tf.zeros([sample_size, latent_dim]), \n",
    "               scale=tf.ones([sample_size, latent_dim]))\n",
    "    targets = None\n",
    "    if sigmoid == 'last':\n",
    "        logits = Normal(loc=tf.matmul(w, z, transpose_b=True), \n",
    "                   scale=observation_var * tf.ones([correlation_count, sample_size]))\n",
    "        t = tf.sigmoid(logits)\n",
    "        targets = 2 * t - 1\n",
    "    elif sigmoid == 'no_sigmoid':\n",
    "        targets = Normal(loc=tf.matmul(w, z, transpose_b=True), \n",
    "                   scale=observation_var * tf.ones([correlation_count, sample_size]))\n",
    "    elif sigmoid == 'first':\n",
    "        t = tf.sigmoid(tf.matmul(w, z, transpose_b=True))\n",
    "        t = 2 * t - 1\n",
    "        targets = Normal(loc=t, \n",
    "                         scale=observation_var * tf.ones([correlation_count, sample_size]))\n",
    "    qz = Normal(loc=tf.Variable(tf.random_normal([sample_size, latent_dim])),\n",
    "            scale=tf.nn.softplus(tf.Variable(tf.random_normal([sample_size, latent_dim]))))\n",
    "    inference = ed.KLqp({z: qz}, data={targets: DATA.T})\n",
    "    inference.run(n_iter=500, n_print=100, n_samples=100)\n",
    "    return qz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bayesian logistics regression\n",
    "# Input:\n",
    "# qz: the distribution of the input variables, either latent/or not dimensions\n",
    "#y_labels: the labels for this supervised learning\n",
    "#latent_dim: the dimension of qz\n",
    "#regression_coef_var: equivalent to regularization term\n",
    "def bayesian_logistics_regression(qz, y_labels, latent_dim, regression_coef_var):\n",
    "    regression_coef = Normal(loc=tf.zeros([1, latent_dim]), \n",
    "               scale=regression_coef_var * tf.ones([1, latent_dim]))\n",
    "    y = Bernoulli(logits=tf.matmul(qz, regression_coef, transpose_b=True))\n",
    "    qcoeff = Normal(loc=tf.Variable(tf.random_normal([1, latent_dim])),\n",
    "            scale=tf.nn.softplus(tf.Variable(tf.random_normal([1, latent_dim]))))\n",
    "    inference = ed.KLqp({regression_coef: qcoeff}, data={y: y_labels})\n",
    "    inference.run(n_iter=500, n_print=100, n_samples=10)\n",
    "    return qcoeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A wrapper that is created to automatically sample training and test set\n",
    "#and compare different models\n",
    "#return the area under the roc curve\n",
    "def dimension_reduction_and_logistics_regression(latent_dim, \n",
    "                                                 dimension_reduction_coef_var, \n",
    "                                                 regression_coef_var, \n",
    "                                                 sigmoid, \n",
    "                                                 observation_var, \n",
    "                                                 DATA, \n",
    "                                                 labels):\n",
    "    train_DATA, train_label, test_DATA, test_label = split_train_test(DATA, labels)\n",
    "    test_label = test_label.reshape((test_label.shape[0],))\n",
    "    qw, qz_train = unsupervised_dimension_reduction(train_DATA, latent_dim, \n",
    "                                              dimension_reduction_coef_var, \n",
    "                                              observation_var, sigmoid)\n",
    "    qcoef = bayesian_logistics_regression(qz_train, train_label, latent_dim, regression_coef_var)\n",
    "    qz_test = learn_latent_given_w(test_DATA, qw, latent_dim, observation_var, sigmoid)\n",
    "    n_samples=100\n",
    "    probas = tf.gather(tf.reduce_mean(tf.stack([tf.sigmoid(tf.matmul(qz_test.sample(), qcoef.sample(), \n",
    "                                                                     transpose_b=True))])))\n",
    "                  for _ in range(n_samples)]), axis=0), 0, axis=1)\n",
    "    score = probas.eval()\n",
    "    fpr, tpr, thresholds = roc_curve(test_label, score)\n",
    "    roc_area = auc(fpr, tpr)\n",
    "    \n",
    "    return roc_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A wrapper for raw bayesian logistics regression\n",
    "#return the area under the roc curve\n",
    "def raw_bayesian_logistics_regression(regression_coef_var, DATA, labels):\n",
    "    train_DATA, train_label, test_DATA, test_label = split_train_test(DATA, labels)\n",
    "    dimension = DATA.shape[1]\n",
    "    test_label = test_label.reshape((test_label.shape[0],))\n",
    "    qcoef = bayesian_logistics_regression(qz, train_label, dimension, regression_coef_var)\n",
    "    probas = tf.gather(tf.reduce_mean(tf.stack([tf.sigmoid(tf.matmul(test_DATA, qcoef.sample(), \n",
    "                                                                     transpose_b=True))])))\n",
    "    score = probas.eval()\n",
    "    fpr, tpr, thresholds = roc_curve(test_label, score)\n",
    "    roc_area = auc(fpr, tpr)\n",
    "    return roc_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regression_coef_var = 1\n",
    "#DATA, labels = \n",
    "#Demo:\n",
    "roc_area = raw_bayesian_logistics_regression(regression_coef_var, DATA, labels)\n",
    "print('The roc area achieved by raw bayesian logistics regression is %f' \n",
    "      % roc_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 20 \n",
    "dimension_reduction_coef_var = 1 \n",
    "regression_coef_var = 1 \n",
    "sigmoid = 'last'\n",
    "observation_var = 0.01\n",
    "latent_dim = 10\n",
    "roc_area = dimension_reduction_and_logistics_regression(latent_dim, \n",
    "                                                        dimension_reduction_coef_var,\n",
    "                                                        regression_coef_var, \n",
    "                                                        sigmoid,\n",
    "                                                        observation_var, \n",
    "                                                        DATA, \n",
    "                                                        labels)\n",
    "print('The roc area achieved by bayesian logistics regression followed by dimension reduction is %f' \n",
    "      % roc_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameter tuning for bayesian logistics regression followed by dimension reduction\n",
    "latent_dims = [10, 20, 30, 40, 50]\n",
    "dimension_reduction_coef_vars = [0.01, 0.1, 1, 2]\n",
    "regression_coef_vars = [0.01, 0.1, 1, 2]\n",
    "sigmoids = ['last', 'before', 'no_sigmoid']\n",
    "observation_vars = [0.01, 0.1, 1, 2]\n",
    "counter = 0\n",
    "performance_dict = {}\n",
    "config_dict = {}\n",
    "for latent_dim in latent_dims:\n",
    "    for dimension_reduction_coef_var in dimension_reduction_coef_vars:\n",
    "        for regression_coef_var in regression_coef_vars:\n",
    "            for sigmoid in sigmoids:\n",
    "                for observation_var in observation_vars:\n",
    "                    config_dict[counter] = [latent_dim, dimension_reduction_coef_var, \n",
    "                                            regression_coef_var, sigmoid, observation_var]\n",
    "                    avg_auc = 0\n",
    "                    for cv_fold in range(5):\n",
    "                        avg_auc += dimension_reduction_and_logistics_regression(latent_dim, \n",
    "                                                        dimension_reduction_coef_var,\n",
    "                                                        regression_coef_var, \n",
    "                                                        sigmoid,\n",
    "                                                        observation_var, \n",
    "                                                        DATA, \n",
    "                                                        labels)\n",
    "                    avg_auc /= 5\n",
    "                    performance_dict[counter] = avg_auc\n",
    "                    counter += 1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regression_coef_vars = [0.01, 0.1, 1, 2]\n",
    "for regression_coef_var in regression_coef_vars:\n",
    "    avg_auc = 0\n",
    "    print('regression coefficient variance=%f' % regression_coef_var)\n",
    "    for cv_fold in range(5):\n",
    "        avg_auc = raw_bayesian_logistics_regression(regression_coef_var, DATA, labels)\n",
    "    avg_auc /= 5\n",
    "    print('Performance: roc=%f' % avg_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
