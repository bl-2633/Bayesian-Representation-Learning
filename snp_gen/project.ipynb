{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the necessary packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "from edward.models import Normal, BernoulliWithSigmoidProbs, Bernoulli, Dirichlet, Empirical\n",
    "from edward.util import Progbar\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as pyplot\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(DATA, y, proportion=0.8):\n",
    "    data_size = len(DATA)\n",
    "    train_size = int(proportion * data_size)\n",
    "    permutation = [i for i in range(data_size)]\n",
    "    random.shuffle(permutation)\n",
    "    train_DATA = DATA[permutation[:train_size]]\n",
    "    train_label = y[permutation[:train_size]]\n",
    "    test_DATA = DATA[permutation[train_size:]]\n",
    "    test_label = y[permutation[train_size:]]\n",
    "    return train_DATA, train_label, test_DATA, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating a data set according to the PSD graphical model\n",
    "#N: the number of SNPs considered\n",
    "#M: the numer of individuals\n",
    "#K: the number of populations/topics, as each individual is a mixture of them\n",
    "#return the data set\n",
    "def generate_PSD_without_label(N, M, K):\n",
    "    alpha = np.ones(K) / K\n",
    "    eta = np.ones(2) / 2\n",
    "    theta = np.random.dirichlet(alpha, size=M)\n",
    "    beta = np.random.dirichlet(eta, size=(K, N))\n",
    "    DATA = []\n",
    "    gamma = np.random.normal(size=(K,))\n",
    "    labels = []\n",
    "    y_raws = []\n",
    "    for m in range(M):\n",
    "        Z_tmp = np.random.multinomial(1, theta[m], size=(2, N))\n",
    "        Z = np.zeros(shape=(2, N), dtype='int32')\n",
    "        X = np.zeros(N, dtype='int32')\n",
    "        y_raw = 0\n",
    "        for _ in range(2):\n",
    "            for n in range(N):\n",
    "                Z[_][n] = np.argmax(Z_tmp[_][n])\n",
    "                p = beta[Z[_][n]][n]\n",
    "                tmp = 1 if np.random.random() <= p[0] else 0\n",
    "                X[n] += tmp\n",
    "        DATA.append(X)\n",
    "    y_raws = theta.dot(gamma)\n",
    "    y_raws = y_raws / np.std(y_raws)\n",
    "    probas = 1 / (1 + np.exp(-y_raws))\n",
    "    labels = (np.random.random(M) < probas).astype(int).reshape(M, 1)\n",
    "    DATA = np.array(DATA, dtype='float')\n",
    "    Z = np.array(Z)\n",
    "    return DATA, Z, theta, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating a data set according to the PSD graphical model\n",
    "#N: the number of SNPs considered\n",
    "#M: the numer of individuals\n",
    "#K: the number of populations/topics, as each individual is a mixture of them\n",
    "#return the data set and labels dependent on the mixtures and SNPs\n",
    "def generate_PSD_with_label(N, M, K):\n",
    "    alpha = np.ones(K) / K\n",
    "    eta = np.ones(2) / 2\n",
    "    theta = np.random.dirichlet(alpha, size=M)\n",
    "    beta = np.random.dirichlet(eta, size=(K, N))\n",
    "    DATA = []\n",
    "    gamma = np.random.normal(size=(K,N))\n",
    "    labels = []\n",
    "    y_raws = []\n",
    "    for m in range(M):\n",
    "        Z_tmp = np.random.multinomial(1, theta[m], size=(2, N))\n",
    "        Z = np.zeros(shape=(2, N), dtype='int32')\n",
    "        X = np.zeros(N, dtype='int32')\n",
    "        y_raw = 0\n",
    "        for _ in range(2):\n",
    "            for n in range(N):\n",
    "                Z[_][n] = np.argmax(Z_tmp[_][n])\n",
    "                p = beta[Z[_][n]][n]\n",
    "                tmp = 1 if np.random.random() <= p[0] else 0\n",
    "                X[n] += tmp\n",
    "                y_raw += tmp * gamma[Z[_][n]][n]\n",
    "        DATA.append(X)\n",
    "        y_raws.append(y_raw)\n",
    "    y_raws = y_raws / np.std(y_raws)\n",
    "    probas = 1 / (1 + np.exp(-y_raws))\n",
    "    labels = (np.random.random(M) < probas).astype(int).reshape(M, 1)\n",
    "    DATA = np.array(DATA, dtype='float')\n",
    "    Z = np.array(Z)\n",
    "    gold_roc_curve = roc_curve(labels, probas)\n",
    "    gold_auc = auc(gold_roc_curve[0], gold_roc_curve[1])\n",
    "    return DATA, labels, Z, theta, beta, gold_roc_curve, gold_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whenever we inference on populations, since it is unsupervised learning,\n",
    "#the order of the inferred population is always a problem\n",
    "#Matching the inferred population\n",
    "def get_best_match(theta_truth, theta_inferred):\n",
    "    assert (theta_truth.shape == theta_inferred.shape)\n",
    "    M = theta_truth.shape[0]\n",
    "    K = theta_truth.shape[1]\n",
    "    #A brute force search, cannot handle cases for K >=6\n",
    "    assert (K <= 6)\n",
    "    permutations = generate_permutation([i for i in range(K)])\n",
    "    best_permutation = None\n",
    "    min_rmse = 1\n",
    "    for permutation in permutations:\n",
    "        theta_permuted = theta_truth[:,permutation]\n",
    "        rmse = np.sqrt(((np.sum(np.square(theta_permuted - theta_inferred))) / M / K))\n",
    "        if rmse < min_rmse:\n",
    "            best_permutation = permutation\n",
    "            min_rmse = rmse\n",
    "    return best_permutation, min_rmse\n",
    "        \n",
    "    \n",
    "#Return a list of list, each list is a permutation\n",
    "def generate_permutation(l):\n",
    "    if len(l) == 1:\n",
    "        return [[l[0]]]\n",
    "    result = []\n",
    "    for element in l:\n",
    "        copy = l[:]\n",
    "        copy.remove(element)\n",
    "        suffix_list = generate_permutation(copy)\n",
    "        for suffix in suffix_list:\n",
    "            result.append([element] + suffix)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximating PSD Decomposition using Bayesian Auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_PSD_with_bayesian_AE(DATA, latent_dim, coef_var, inference_method='KLqp'):\n",
    "    sample_size = DATA.shape[0]\n",
    "    SNP_count = DATA.shape[1]\n",
    "    w = Normal(loc=tf.zeros([SNP_count, latent_dim]), \n",
    "               scale=coef_var * tf.ones([SNP_count, latent_dim]))\n",
    "    z = Dirichlet(tf.ones([sample_size, latent_dim]) / latent_dim)\n",
    "    x = tf.add(BernoulliWithSigmoidProbs(tf.matmul(w, z, transpose_b=True)), \n",
    "                   BernoulliWithSigmoidProbs(tf.matmul(w, z, transpose_b=True)))\n",
    "    if inference_method=='KLqp':\n",
    "        qw = Normal(loc=tf.Variable(tf.random_normal([SNP_count, latent_dim])),\n",
    "            scale=tf.nn.softplus(tf.Variable(tf.random_normal([SNP_count, latent_dim]))))\n",
    "        #The random initialization coefficient 0.01 is hand-picked here\n",
    "        #In general, KLqp in this setting is extremely fragile; a slightly larger\n",
    "        #coefficient will result in nan in loss\n",
    "        #Even 0.01 sometimes does not work; the edward seed is also manually picked\n",
    "        #to make a working example\n",
    "        qz = Dirichlet(tf.Variable((tf.zeros([sample_size, latent_dim]) \n",
    "                               + tf.random_uniform([sample_size, latent_dim]) * 0.01)\n",
    "                               / latent_dim))\n",
    "        inference = ed.KLqp({w: qw, z: qz}, data={x: DATA.T})\n",
    "        #We have also tried different optimizers; however, none of them is better than\n",
    "        #the built-in\n",
    "        #optimizer = tf.train.RMSPropOptimizer(0.01)\n",
    "        #optimizer = tf.train.AdamOptimizer()\n",
    "        #inference.initialize(optimizer=optimizer)\n",
    "        inference.run(n_iter=50000, n_print=100, n_samples=100)\n",
    "        return qw, qz\n",
    "    else:\n",
    "        T = 5000\n",
    "        qw = Empirical(params=tf.Variable(tf.zeros([T, SNP_count, latent_dim])))\n",
    "        qz = Empirical(params=tf.Variable(tf.zeros([T, sample_size, latent_dim])))\n",
    "        inference = None\n",
    "        if inference_method == 'HMC':\n",
    "            inference = ed.HMC({w: qw, z: qz}, {x: DATA.T})\n",
    "        elif inference_method == 'Gibbs':\n",
    "            inference = ed.Gibbs({w: qw, z: qz}, {x: DATA.T})\n",
    "        inference.run(step_size=0.5 / sample_size, n_steps=10)\n",
    "        return qw, qz\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "ed.set_seed(1)\n",
    "N, M, K = 100, 10, 3\n",
    "alpha = np.ones(K) / K\n",
    "DATA, Z, theta, beta = generate_PSD_without_label(N, M, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [100%] ██████████████████████████████ Elapsed: 157s | Loss: 650.100\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "coef_var = 2\n",
    "qw, qz = approximate_PSD_with_bayesian_AE(DATA, K, coef_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.30678025  0.34347826  0.34974   ]\n",
      " [ 0.28955489  0.4168213   0.29362366]\n",
      " [ 0.36547545  0.36289462  0.27163002]\n",
      " [ 0.34359479  0.3145403   0.34186471]\n",
      " [ 0.3109794   0.36745816  0.32156312]\n",
      " [ 0.29541248  0.37457874  0.33000848]\n",
      " [ 0.37628451  0.31937417  0.30434155]\n",
      " [ 0.28919294  0.30996752  0.40083873]\n",
      " [ 0.35698453  0.3219856   0.32102877]\n",
      " [ 0.37249371  0.27115145  0.35635456]]\n"
     ]
    }
   ],
   "source": [
    "inferred_theta_mean = np.mean(qz.sample(10000).eval(), axis=0)\n",
    "print(inferred_theta_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline rmse 0.419915\n",
      "Result obtained by KLqp: 0.410329\n"
     ]
    }
   ],
   "source": [
    "best_permutation, min_rmse = get_best_match(theta, inferred_theta_mean)\n",
    "baseline_theta = np.ones([M, K]) / K\n",
    "baseline = np.sqrt(np.sum(np.square(baseline_theta - theta)) / M / K)\n",
    "print('Baseline rmse %f' % baseline)\n",
    "print('Result obtained by KLqp: %f' % min_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 3 and 4 for 'inference_3/sample_102/Dirichlet_9/log_prob/mul' (op: 'Mul') with input shapes: [10,3], [10,4].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 3 and 4 for 'inference_3/sample_102/Dirichlet_9/log_prob/mul' (op: 'Mul') with input shapes: [10,3], [10,4].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-75d5b444c6b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapproximate_PSD_with_bayesian_AE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'HMC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-f1cfe0182d95>\u001b[0m in \u001b[0;36mapproximate_PSD_with_bayesian_AE\u001b[0;34m(DATA, latent_dim, coef_var, inference_method)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minference_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Gibbs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0minference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGibbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqz\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDATA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mqw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/edward/inferences/inference.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, variables, use_coordinator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mPassed\u001b[0m \u001b[0minto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/edward/inferences/hmc.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, step_size, n_steps, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# store global scope for log joint calculations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inference\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHMC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/edward/inferences/monte_carlo.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_accept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"n_accept\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_accept_over_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_accept\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_accept\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/edward/inferences/hmc.py\u001b[0m in \u001b[0;36mbuild_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m     new_sample, new_r_sample = leapfrog(old_sample, old_r_sample,\n\u001b[1;32m     90\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_joint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                                         self.n_steps)\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Calculate acceptance ratio.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/edward/inferences/hmc.py\u001b[0m in \u001b[0;36mleapfrog\u001b[0;34m(z_old, r_old, step_size, log_joint, n_steps)\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[0mr_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m   \u001b[0mgrad_log_joint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_joint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitervalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/edward/inferences/hmc.py\u001b[0m in \u001b[0;36m_log_joint\u001b[0;34m(self, z_sample)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mz_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_swap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m       \u001b[0mlog_joint\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_swap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value, name)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \"\"\"\n\u001b[0;32m--> 692\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py\u001b[0m in \u001b[0;36m_call_log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/ops/distributions/transformed_distribution.py\u001b[0m in \u001b[0;36m_log_prob\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0mildj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_injective\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish_log_prob_for_one_fiber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mildj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     lp_on_fibers = [\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/ops/distributions/transformed_distribution.py\u001b[0m in \u001b[0;36m_finish_log_prob_for_one_fiber\u001b[0;34m(self, y, x, ildj)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;34m\"\"\"Finish computation of log_prob on one element of the inverse image.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_rotate_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotate_right\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_maybe_event_override\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m       \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reduce_event_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value, name)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \"\"\"\n\u001b[0;32m--> 692\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py\u001b[0m in \u001b[0;36m_call_log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/ops/distributions/util.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       \u001b[0m_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_additional_note\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/ops/distributions/dirichlet.py\u001b[0m in \u001b[0;36m_log_prob\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdistribution_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAppendDocstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dirichlet_sample_note\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_unnormalized_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdistribution_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAppendDocstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dirichlet_sample_note\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/ops/distributions/dirichlet.py\u001b[0m in \u001b[0;36m_log_unnormalized_prob\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_log_unnormalized_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_assert_valid_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_log_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    892\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1115\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Case: Dense * Sparse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   2724\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 2726\u001b[0;31m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   2727\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venv/foo/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 3 and 4 for 'inference_3/sample_102/Dirichlet_9/log_prob/mul' (op: 'Mul') with input shapes: [10,3], [10,4]."
     ]
    }
   ],
   "source": [
    "#There is a reported bug of HMC cannot get the value of latent dirichlet dimension correct\n",
    "#After I have implemented the model, I found that other people have also complained about\n",
    "#it before\n",
    "qw, qz = approximate_PSD_with_bayesian_AE(DATA, K, coef_var, inference_method='HMC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, this model does not work in Edward, since there is no robust and effective inference algorithm for it. Furthermore, it is still unknown whether it will be a reasonable approximition even if we are able to calculate the posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Probablisitc PCA followed by Bayesian Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unsupervised Probablistic Dimension Reduction\n",
    "def unsupervised_dimension_reduction(DATA, latent_dim, dimension_reduction_coef_var, \n",
    "                                    observation_var, sigmoid=False):\n",
    "    sample_size = DATA.shape[0]\n",
    "    SNP_count = DATA.shape[1]\n",
    "    if sigmoid:\n",
    "        observation_var = None\n",
    "    w = Normal(loc=tf.zeros([SNP_count, latent_dim]), \n",
    "               scale=dimension_reduction_coef_var * tf.ones([SNP_count, latent_dim]))\n",
    "    z = Normal(loc=tf.zeros([sample_size, latent_dim]), \n",
    "               scale=tf.ones([sample_size, latent_dim]))\n",
    "    if not sigmoid:\n",
    "        x = Normal(loc=tf.matmul(w, z, transpose_b=True), \n",
    "                   scale=observation_var * tf.ones([SNP_count, sample_size]))\n",
    "    else:\n",
    "        x = tf.add(BernoulliWithSigmoidProbs(tf.matmul(w, z, transpose_b=True)), \n",
    "                   BernoulliWithSigmoidProbs(tf.matmul(w, z, transpose_b=True)))\n",
    "    qw = Normal(loc=tf.Variable(tf.random_normal([SNP_count, latent_dim])),\n",
    "            scale=tf.nn.softplus(tf.Variable(tf.random_normal([SNP_count, latent_dim]))))\n",
    "    qz = Normal(loc=tf.Variable(tf.random_normal([sample_size, latent_dim])),\n",
    "            scale=tf.nn.softplus(tf.Variable(tf.random_normal([sample_size, latent_dim]))))\n",
    "    inference = ed.KLqp({w: qw, z: qz}, data={x: DATA.T})\n",
    "    inference.run(n_iter=500, n_print=100, n_samples=100)\n",
    "    return qw, qz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_latent_given_w(DATA, qw, latent_dim, observation_var, sigmoid=False):\n",
    "    sample_size = DATA.shape[0]\n",
    "    SNP_count = DATA.shape[1]\n",
    "    z = Normal(loc=tf.zeros([sample_size, latent_dim]), \n",
    "               scale=tf.ones([sample_size, latent_dim]))\n",
    "    if not sigmoid:\n",
    "        x = Normal(loc=tf.matmul(qw, z, transpose_b=True), \n",
    "                   scale=observation_var * tf.ones([SNP_count, sample_size]))\n",
    "    else:\n",
    "        x = tf.add(BernoulliWithSigmoidProbs(tf.matmul(qw, z, transpose_b=True)), \n",
    "                   BernoulliWithSigmoidProbs(tf.matmul(qw, z, transpose_b=True)))\n",
    "    qz = Normal(loc=tf.Variable(tf.random_normal([sample_size, latent_dim])),\n",
    "            scale=tf.nn.softplus(tf.Variable(tf.random_normal([sample_size, latent_dim]))))\n",
    "    inference = ed.KLqp({z: qz}, data={x: DATA.T})\n",
    "    inference.run(n_iter=500, n_print=100, n_samples=10)\n",
    "    return qz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_logistics_regression(qz, y_labels, latent_dim, regression_coef_var):\n",
    "    regression_coef = Normal(loc=tf.zeros([1, latent_dim]), \n",
    "               scale=regression_coef_var * tf.ones([1, latent_dim]))\n",
    "    y = Bernoulli(logits=tf.matmul(qz, regression_coef, transpose_b=True))\n",
    "    qcoeff = Normal(loc=tf.Variable(tf.random_normal([1, latent_dim])),\n",
    "            scale=tf.nn.softplus(tf.Variable(tf.random_normal([1, latent_dim]))))\n",
    "    inference = ed.KLqp({regression_coef: qcoeff}, data={y: y_labels})\n",
    "    inference.run(n_iter=500, n_print=100, n_samples=10)\n",
    "    return qcoeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_reduction_and_logistics_regression(latent_dim, dimension_reduction_coef_var, \n",
    "                                                 regression_coef_var, sigmoid, \n",
    "                                                 observation_var, DATA, labels):\n",
    "    if sigmoid:\n",
    "        observation_var = None\n",
    "    train_DATA, train_label, test_DATA, test_label = split_train_test(DATA, labels)\n",
    "    test_label = test_label.reshape((test_label.shape[0],))\n",
    "    qw, qz_train = unsupervised_dimension_reduction(train_DATA, latent_dim, \n",
    "                                              dimension_reduction_coef_var, \n",
    "                                              observation_var, sigmoid)\n",
    "    qcoef = bayesian_logistics_regression(qz_train, train_label, latent_dim, regression_coef_var)\n",
    "    qz_test = learn_latent_given_w(test_DATA, qw, latent_dim, observation_var, sigmoid)\n",
    "    n_samples=100\n",
    "    probas = tf.gather(tf.reduce_mean(tf.stack([tf.sigmoid(tf.matmul(qz_test.sample(), qcoef.sample(), transpose_b=True))\n",
    "                  for _ in range(n_samples)]), axis=0), 0, axis=1)\n",
    "    score = probas.eval()\n",
    "    fpr, tpr, thresholds = roc_curve(test_label, score)\n",
    "    roc_area = auc(fpr, tpr)\n",
    "    \n",
    "    return roc_area\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M, K = 1000, 100, 3\n",
    "DATA, labels, Z, theta, beta, gold_roc_curve, gold_auc = generate_PSD_with_label(N, M, K)\n",
    "DATA[0][0] = np.nan\n",
    "DATA[1][0] = np.nan\n",
    "DATA[3][0] = np.nan\n",
    "DATA[5][2] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [100%] ██████████████████████████████ Elapsed: 9s | Loss: 0.000\n",
      "500/500 [100%] ██████████████████████████████ Elapsed: 5s | Loss: 7.011\n",
      "500/500 [100%] ██████████████████████████████ Elapsed: 2s | Loss: 0.000\n",
      "0.428571428571\n"
     ]
    }
   ],
   "source": [
    "roc_area = dimension_reduction_and_logistics_regression(50, 1, 1, True, 1, DATA, labels)\n",
    "print(roc_area)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
